{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> pyLDPC: Sound Coding & Decoding Module Construction </h1> \n",
    "\n",
    "## update:  03/28/16 - v.0.8.0\n",
    "\n",
    "<b><font color=\"red\"> Since version 0.7: Coding and decoding functions take tG (Transposed G) instead of G, the coding matrix. Functions that construct it (CodingMatrix and CodingMatrix_systematic) return tG instead of G as well. </font></b> \n",
    "\n",
    "<br> \n",
    "\n",
    "<font color=#0101DF><b> Note: </b> </font> \n",
    "\n",
    " <b> Github doesn't support HTML audio in jupyter's cells, I invite you to open this notebook in <a href=\"http://nbviewer.jupyter.org/github/janatiH/pyldpc/blob/master/pyLDPC-Sound-Construction.ipynb?flush_cache=true\"> nbviewer </a></b> \n",
    "\n",
    "This notebook introduces the sub-module <i>Sound</i> of pyLDPC: ldpc_sound.\n",
    "It explains what each function does and how to use it. If you're more interested in using the module, you may follow the <a href=\"http://nbviewer.jupyter.org/github/janatiH/pyldpc/blob/master/pyLDPC-Tutorial-Sound.ipynb?flush_cache=true\"> User's guide: pyLDPC-Sound Tutorial</a>\n",
    "\n",
    "All the functions defined below can be called py importing the sub-module ldpc_sound:\n",
    "```python\n",
    "import pyldpc.ldpc_sound as ldpc_sound\n",
    "ldpc_sound.SoundCoding(....)\n",
    "```\n",
    "Or once and for all import everything so that you can follow the tutorial mentioned above.\n",
    "```python\n",
    "from pyldpc.ldpc_sound import*\n",
    "SoundCoding(....)\n",
    "```\n",
    "\n",
    "We'll consider audio files in <b><font color=#0101DF> wav </font></b> format. To read wav files, we'll use the module <i><font color=#0101DF> wavfile </font></i> in \n",
    "the package <i><font color=#0101DF> scipy.io </font></i>.\n",
    "\n",
    "If you're familiar with audio files (read as numpy.arrays) you should probably skip the first section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pyldpc\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- What does a wav file look like ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a wavfile you might (or even should) recognize:\n",
    "\n",
    "<br>\n",
    "\n",
    "<audio controls src=\"Sound/got/got.wav\" type=\"audio/wav\">\n",
    "</audio>\n",
    "\n",
    "<br>\n",
    "\n",
    "The function <i> read </i> in the module <i> wavfile </i> takes one argument (the wav file's path) and returns the tuple <i> freq, data </i>, where freq is the track's frequency (or sample rate) and data is the numpy.array storing the sound's information. Changing the frequency only affects the way the file is read. The greater the frequency, the more samples are read per second. In the example below, if you divide <i>length</i> by <i>frequency</i>: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.63374149659865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4482048 / 44100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which corresponds to the song's length in seconds (it rounds up to 1mn42s).\n",
    "In practice, we'll be coding and decoding parts of an audio-array using <i>frequency</i> as delimiter. \n",
    "Let's see what <i> got </i> looks like in numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency: 44100 samples/sec\n",
      "\n",
      "Data:\n",
      " [[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ..., \n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "\n",
      "Data's shape: (4482048, 2)\n",
      "\n",
      "Data's type: int16\n"
     ]
    }
   ],
   "source": [
    "freq_got, got_data = wavfile.read(\"Sound/got/got.wav\")\n",
    "print(\"Frequency: {} samples/sec\".format(freq_got))\n",
    "print(\"\\nData:\\n\",got_data)\n",
    "print(\"\\nData's shape:\",got_data.shape)\n",
    "print(\"\\nData's type:\",got_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To conclude about frequency, the filtered array\n",
    "```python\n",
    "got_data[freq_got : 3*freq_got] \n",
    "```\n",
    "for example, is a <font color=#0101DF><b>2.freq_got</b></font> sized array. If saved with the <font color=#0101DF><b>same frequency freq_got</b></font> and then read, the wav file reading will last for <font color=#0101DF><b>2 seconds.</b></font> In other words, coding and decoding a 1 second track, is technically coding and decoding an array of freq_got int16 numbers. \n",
    "\n",
    "So <i> got'</i>s data is a 2D-array of int16 elements. If you keep only one of the columns of <i>got</i>, you may not realize any change in the track. That's because the number of columns is actually the number of <i>channels</i>. One channel is enough to construct a wav file, the second channel is not needed except for the <i>stereo effect</i>. \n",
    "\n",
    "That's why, <b>this submodule will only code and decode the first channel (i.e the first column) of a wav file</b> (in case it's a setero).\n",
    "\n",
    "Let's make <i>got</i> a 1D-array version (no stero effect) of the original track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency: 44100 samples/sec\n",
      "\n",
      "Data:\n",
      " [0 0 0 ..., 0 0 0]\n",
      "\n",
      "Data's shape: (4482048,)\n",
      "\n",
      "Data's type: int16\n"
     ]
    }
   ],
   "source": [
    "got = got_data[:,0]\n",
    "print(\"Frequency: {} samples/sec\".format(freq_got))\n",
    "print(\"\\nData:\\n\",got)\n",
    "print(\"\\nData's shape:\",got.shape)\n",
    "print(\"\\nData's type:\",got.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 - Audio-array to binary array\n",
    "\n",
    "\n",
    "This is it. We've got a 4482048 length array of <b>int16</b> numbers (which also cover negative integers): i.e each number is in:\n",
    "\n",
    "<img src=\"Equations/SoundC1.png\">\n",
    "\n",
    "In order to convert each of these numbers to binary arrays, they must be <b> unsigned integers </b>. \n",
    "That's why we'll apply a sort of <i>translation</i> by 2^15 so that each number of the array will be included in:\n",
    "\n",
    "<img src=\"Equations/SoundC2.png\">\n",
    "\n",
    "Then, each number can be written in a binary array of 17 bits. In binary, <i>got</i> will be written as a 2D-array shaped (<i>length</i>,17)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Audio2Bin(audio_array):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts the first audio channel (first column) of an int16 audio_array to a 17-bits binary form.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio-array: must be int16. May be 2D-array but the function only converts one channel. \n",
    "    \n",
    "    returns:\n",
    "    - 17 bits binary audio-array shaped (length,17) where length is the audio_array's length. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #### Keep the first channel of the audio file only:\n",
    "    if len(audio_array.shape)>1:\n",
    "        audio = audio_array[:,0]\n",
    "    else:\n",
    "        audio = audio_array\n",
    "        \n",
    "    length = audio.size \n",
    "    \n",
    "    #### Translate audio by 2^15 so as to make its dtype unsigned.\n",
    "    audio = audio + 2**15\n",
    "    \n",
    "    audio_bin = np.zeros(shape=(length,17),dtype=int)\n",
    "    for i in range(length):\n",
    "        audio_bin[i,:] = pyldpc.ldpcalgebra.int2bitarray(audio[i],17)\n",
    "        \n",
    "    return audio_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Bin2Audio(audio_bin):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts a 17-bits binary audio array to an int16 1D-(one channel) audio_array.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_bin: 17 bits binary array shaped (length,17). \n",
    "    \n",
    "    returns:\n",
    "    - int16 1D-audio-array of size = length.\n",
    "    \n",
    "    \"\"\"\n",
    "            \n",
    "    length = audio_bin.shape[0] \n",
    "    \n",
    "    audio = np.zeros(length,dtype=int)\n",
    "    \n",
    "    for i in range(length):\n",
    "        audio[i] = pyldpc.ldpcalgebra.bitarray2int(audio_bin[i,:])\n",
    "    \n",
    "    #### Translate audio by - 2^15 so as to make its dtype signed int16.\n",
    "\n",
    "    audio = audio - 2**15\n",
    "\n",
    "    return audio.astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding & Decoding using small matrices \n",
    "\n",
    "## 3 - Coding Audio files\n",
    "\n",
    "Now that our audio file is a (length,17) binary array, we can encode each 17-bits binary array with a 17 rows coding matrix G. But in order to \"visualize\" the noisy audio, G must be systematic so that the 17 first bits of each codeword can still be identified after coding. The coding function <i>SoundCoding</i> adds a AWGN with a specified SNR. SNR: Signal-Noise Ratio, SNR = 10log(1/variance) in decibels.\n",
    "\n",
    "The coding function <i>SoundCoding</i> is actually similar to <i>ImageCoding</i>, since it gathers the 17 noisy bits of n-sized codewords <i>on the left</i> of the noisy array so that the \"noisy\" form of the original song is reconstructed. The rest of the noisy-array (i.e the redundant bits) are dropped (pure noise).\n",
    "\n",
    "<font color=\"red\">Since v7.0, SoundCoding takes tG, transposed coding matrix tG instead of G. </font>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SoundCoding(tG,audio_bin,snr):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Codes a binary audio array (Therefore must be a 2D-array shaped (length,17)). It is reshaped so as to match tG's dimensions. \n",
    "    Then a gaussian noise N(0,snr) is added to the codeword.\n",
    "    \n",
    "    Remember SNR: Signal-Noise Ratio: SNR = 10log(1/variance) in decibels of the AWGN used in coding.\n",
    "\n",
    "    Of course, \"listening\" to an audio file with n-bits array is impossible, that's why if Coding Matrix G is systematic,\n",
    "    reading the noisy sound can be possible by gathering the 17 first bits of each \n",
    "    n-bits codeword to the left, the redundant bits are dropped. \n",
    "    \n",
    "    returns  a tuple: the (X,n) coded audio, and the noisy one in binary form (length).\n",
    "    \n",
    "    Parameters:\n",
    "\n",
    "    tG: Transposed Coding Matrix G - must be systematic. See CodingMatrix_systematic.\n",
    "    audio_bin: 2D-array of a binary audio shaped (length,17).\n",
    "    SNR: Signal-Noise Ratio, SNR = 10log(1/variance) in decibels of the AWGN used in coding.\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    Tuple: binary noisy_audio, coded_audio\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n,k = tG.shape\n",
    "    length = audio_bin.shape[0]\n",
    "    \n",
    "    ratio = (length*17)//k\n",
    "    rows = ceil(length*17/k)\n",
    "    rest = (length*17)%k\n",
    "        \n",
    "    audio_bin_reshaped = np.zeros((rows,k),dtype=int)\n",
    "\n",
    "    audio_bin_reshaped[:ratio,:k] = audio_bin.flatten()[:ratio*k].reshape(ratio,k)\n",
    "    \n",
    "    if rest >0:\n",
    "        audio_bin_reshaped[-1,:rest] = audio_bin.flatten()[-rest:]\n",
    "        \n",
    "    if n>=100 and not type(tG)==scipy.sparse.csr_matrix:\n",
    "        warnings.warn(\"Using scipy.sparse.csr_matrix format is highly recommanded when computing coding and decoding with large matrices to speed up calculations.\")\n",
    "        \n",
    "    if n>=100 and not (tG[:k,:]==np.identity(k)).all():\n",
    "        raise ValueError(\"G must be Systematic if n>=100 (for later decoding, solving tG.tv = tx for images has a O(n^3) complexity.)\")\n",
    "       \n",
    "\n",
    "    coded_audio = np.zeros(shape=(rows+1,n))\n",
    "    coded_audio[-1,0]=length\n",
    "    \n",
    "    \n",
    "    for i in range(rows):\n",
    "        coded_number = pyldpc.Coding(tG,audio_bin_reshaped[i,:],snr)\n",
    "        coded_audio[i,:] = coded_number\n",
    "                \n",
    "    noisy_audio = (coded_audio[:,:k]<0).astype(int).flatten()[:length*17].reshape(length,17)\n",
    "    \n",
    "    return coded_audio,noisy_audio\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Decoding audio files\n",
    "\n",
    "Decoding functin <i> SoundDecoding </i> uses parity-check matrix to decode y=x+e and find the noise-free codeword, but also needs coding matrix G to solve coding equation tGtv = tx and find original 17 bits message v if G is not systematic. \n",
    "\n",
    "When all original 17 bits numbers are decoded, the function returns the audio file in its \"reading\" format int16.\n",
    "\n",
    "<br> \n",
    "<font color=\"blue\"> SoundDecoding uses a slightly different version of decoding functions (pyldpc.Decoding_BP_ext, pyldpc.Decoding_logBP_ext) where some \"static\" parameters related to H are passed to the decoding functions in order to speed up computing. These optimization changes are hidden so that the user will not suffer from radical syntax changes in new releases.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SoundDecoding(tG,H,audio_coded,snr,max_iter=1,log=1):\n",
    "    \n",
    "    \"\"\" \n",
    "    Sound Decoding Function. Taked the 2-D binary coded audio array where each element is a codeword n-bits array and decodes \n",
    "    every one of them. Needs H to decode and G to solve v.G = x where x is the codeword element decoded by the function\n",
    "    itself. When v is found for each codeword, the decoded audio is returned in binary form. It can then be compared to audio_bin \n",
    "    with BER_audio function.\n",
    "    \n",
    "    Parameters: \n",
    "    \n",
    "    tG: Transposed Coding Matrix must be systematic.\n",
    "    H: Parity-Check Matrix (Decoding matrix). \n",
    "    audio_coded: binary coded audio returned by the function SoundCoding. Must be shaped (length, n) where n is a\n",
    "                the length of a codeword (also the number of H's columns)\n",
    "    \n",
    "    snr: Signal-Noise Ratio: SNR = 10log(1/variance) in decibels of the AWGN used in coding.\n",
    "    \n",
    "    log: (optional, default = True), if True, Full-log version of BP algorithm is used. \n",
    "    max_iter: (optional, default =1), number of iterations of decoding. increase if snr is < 5db. \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n,k = tG.shape\n",
    "    rows,N = audio_coded.shape\n",
    "    length = int(audio_coded[-1,0])\n",
    "    \n",
    "    if N!=n:\n",
    "        raise ValueError('Coded Image must have the same number of columns as H')\n",
    "        \n",
    "    if n>=100 and not type(tG)==scipy.sparse.csr_matrix:\n",
    "        warnings.warn(\"Using scipy.sparse.csr_matrix format is highly recommanded when computing coding and decoding with large matrices to speed up calculations.\")\n",
    "        \n",
    "    if n>=100 and not (tG[:k,:]==np.identity(k)).all():\n",
    "        raise ValueError(\"G must be Systematic. Solving tG.tv = tx for images has a O(n^3) complexity.\")\n",
    "            \n",
    "    audio_decoded = np.zeros(shape=(rows-1,k),dtype = int)\n",
    "\n",
    "    if log:\n",
    "        DecodingFunction = pyldpc.Decoding_logBP\n",
    "    else:\n",
    "        DecodingFunction = pyldpc.Decoding_BP\n",
    "       \n",
    "    BitsNodes = pyldpc.ldpcalgebra.BitsAndNodes(H)\n",
    "\n",
    "    for j in range(rows-1):\n",
    "\n",
    "        decoded = DecodingFunction(H,BitsNodes,audio_coded[j,:],snr,max_iter)\n",
    "\n",
    "        audio_decoded[j,:] = decoded[:k]\n",
    "    \n",
    "    audio_decoded = audio_decoded.flatten()[:length*17].reshape(length,17)\n",
    " \n",
    "    return audio_decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bit Error Rate - Audio: \n",
    "Function that will give us an idea about how accurate our decoding is by comparing the original and the decoded audio files bit by bit. It returns the rate of false bits over all bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BER_audio(original_audio_bin,decoded_audio_bin):\n",
    "    \"\"\" \n",
    "    \n",
    "    Computes Bit-Error-Rate (BER) by comparing 2 binary audio arrays.\n",
    "    The ratio of bit errors over total number of bits is returned.\n",
    "    \n",
    "    \"\"\"\n",
    "    if not original_audio_bin.shape == decoded_audio_bin.shape:\n",
    "        raise ValueError('Original and decoded audio files\\' shapes don\\'t match !')\n",
    "        \n",
    "    length, k = original_audio_bin.shape \n",
    "    \n",
    "    total_bits  = np.prod(original_audio_bin.shape)\n",
    "\n",
    "    errors_bits = sum(abs(original_audio_bin-decoded_audio_bin).reshape(length*k))\n",
    "    \n",
    "    BER = errors_bits/total_bits \n",
    "    \n",
    "    return(BER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Application : \n",
    "<a href=\"http://nbviewer.jupyter.org/github/janatiH/pyldpc/blob/master/pyLDPC-Tutorial-Sound.ipynb?flush_cache=true\"> User's guide: pyLDPC-Sound Tutorial</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
